{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T13:22:45.351641Z",
     "start_time": "2019-02-07T13:22:45.346606Z"
    }
   },
   "source": [
    "<h1><center> Deep Learning Gender Detection </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T13:28:16.307116Z",
     "start_time": "2019-02-07T13:28:16.302923Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T13:31:30.181525Z",
     "start_time": "2019-02-07T13:31:30.120086Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "\tdef __init__(self, filename_data, filename_gender, nbdata, L2normalize=False, batchSize=128):\n",
    "\t\t# ---- Attributes ----\n",
    "\t\tself.nbdata = nbdata\n",
    "\t\t# taille des images 48*48 pixels en niveau de gris\n",
    "\t\tself.dim = 2304\n",
    "\t\tself.data = None\n",
    "\t\tself.label = None\n",
    "\t\tself.x = None\n",
    "\t\tself.y_desired = None\n",
    "\t\t\t\n",
    "\t\tself.batchSize = batchSize\n",
    "\t\t\n",
    "\t\tself.curPos = 0\t\n",
    "\t\t\t\t\n",
    "\t\tf = open(filename_data, 'rb')\n",
    "\t\tself.data = np.empty([nbdata, self.dim], dtype=np.float32)\n",
    "\t\tfor i in range(nbdata):\n",
    "\t\t\tself.data[i,:] = np.fromfile(f, dtype=np.uint8, count=self.dim)\n",
    "\t\tf.close()\n",
    "\n",
    "\n",
    "\t\tf = open(filename_gender, 'rb')\n",
    "\t\tself.label = np.empty([nbdata, 2], dtype=np.float32)\n",
    "\t\tfor i in range(nbdata):\n",
    "\t\t\tself.label[i,:] = np.fromfile(f, dtype=np.float32, count=2)\n",
    "\t\tf.close()\n",
    "\t\t\n",
    "\t\tprint ('nb data : ', self.nbdata)\n",
    "\t\t\n",
    "\t\ttmpdata = np.empty([1, self.dim], dtype=np.float32)\n",
    "\t\ttmplabel = np.empty([1, 2], dtype=np.float32)\n",
    "\t\tarr = np.arange(nbdata)\n",
    "\t\tnp.random.shuffle(arr)\n",
    "\t\ttmpdata = self.data[arr[0],:]\n",
    "\t\ttmplabel = self.label[arr[0],:]\n",
    "\t\tfor i in range(nbdata-1):\n",
    "\t\t\tself.data[arr[i],:] = self.data[arr[i+1],:] \n",
    "\t\t\tself.label[arr[i],:] = self.label[arr[i+1],:] \n",
    "\t\tself.data[arr[nbdata-1],:] = tmpdata\n",
    "\t\tself.label[arr[nbdata-1],:] = tmplabel \n",
    "\t\t\n",
    "\t\tif L2normalize:\n",
    "\t\t\tself.data /= np.sqrt(np.expand_dims(np.square(self.data).sum(axis=1), 1))\n",
    "\t\t\n",
    "\t\t\n",
    "\tdef NextTrainingBatch(self):\n",
    "\t\tif self.curPos + self.batchSize > self.nbdata:\n",
    "\t\t\tself.curPos = 0\n",
    "\t\txs = self.data[self.curPos:self.curPos+self.batchSize,:]\n",
    "\t\tys = self.label[self.curPos:self.curPos+self.batchSize,:]\n",
    "\t\tself.curPos += self.batchSize\n",
    "\t\treturn xs,ys\n",
    "\t\n",
    "\t\n",
    "\tdef mean_accuracy(self, TFsession,loc_acc,loc_x,loc_y,loc_istrain):\n",
    "\t\tacc = 0\n",
    "\t\tfor i in range(0, self.nbdata, self.batchSize):\n",
    "\t\t\tcurBatchSize = min(self.batchSize, self.nbdata - i)\n",
    "\t\t\tdict = {loc_x:self.data[i:i+curBatchSize,:],loc_y:self.label[i:i+curBatchSize,:],loc_istrain:False}\n",
    "\t\t\tacc += TFsession.run(loc_acc, dict) * \tcurBatchSize\n",
    "\t\tacc /= self.nbdata\n",
    "\t\treturn acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T13:32:49.602625Z",
     "start_time": "2019-02-07T13:32:49.470386Z"
    }
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, name):\n",
    "\twith tf.name_scope('summaries'):\n",
    "\t\tmean = tf.reduce_mean(var)\n",
    "\t\ttf.summary.scalar( name + '/mean', mean)\n",
    "\t\twith tf.name_scope('stddev'):\n",
    "\t\t\tstddev = tf.sqrt(tf.reduce_sum(tf.square(var - mean)))\n",
    "\t\ttf.summary.scalar( name + '/sttdev' , stddev)\n",
    "\t\ttf.summary.scalar( name + '/max' , tf.reduce_max(var))\n",
    "\t\ttf.summary.scalar( name + 'min/' , tf.reduce_min(var))\n",
    "\t\ttf.summary.histogram(name, var)\n",
    "\n",
    "def fc(tensor, output_dim, IsTrainingMode, name,KP_dropout, act=tf.nn.relu):\n",
    "\twith tf.name_scope(name):\n",
    "\t\tinput_dim = tensor.get_shape()[1].value\n",
    "\t\tWinit = tf.truncated_normal([input_dim, output_dim], stddev=np.sqrt(2.0/input_dim))\n",
    "\t\tW = tf.Variable(Winit)\n",
    "\t\tprint (name,'input  ',tensor)\n",
    "\t\tprint (name,'W  ',W.get_shape())\n",
    "\t\tvariable_summaries(W, name + '/W')\n",
    "\t\tBinit = tf.constant(0.0, shape=[output_dim])\n",
    "\t\tB = tf.Variable(Binit)\n",
    "\t\tvariable_summaries(B, name + '/B')\n",
    "\t\ttensor = tf.matmul(tensor, W) + B\n",
    "\t\ttensor = act(tensor)\n",
    "\t\tif KP_dropout != 1.0:\n",
    "\t\t\ttensor = tf.cond(IsTrainingMode,lambda: tf.nn.dropout(tensor, KP_dropout), lambda: tf.identity(tensor))\t\n",
    "\n",
    "\treturn tensor\n",
    "\n",
    "def conv(tensor, outDim, filterSize, stride, IsTrainingMode, name,KP_dropout, act=tf.nn.relu):\n",
    "\twith tf.name_scope(name):\n",
    "\t\tinDimH = tensor.get_shape()[1].value\n",
    "\t\tinDimW = tensor.get_shape()[2].value\n",
    "\t\tinDimD = tensor.get_shape()[3].value\n",
    "\t\tWinit = tf.truncated_normal([filterSize, filterSize, inDimD, outDim], stddev=np.sqrt(2.0/(inDimH*inDimW*inDimD)))\n",
    "\t\tW = tf.Variable(Winit)\n",
    "\t\tprint (name,'input  ',tensor)\n",
    "\t\tprint (name,'W  ',W.get_shape())\n",
    "\t\tvariable_summaries(W, name + '/W')\n",
    "\t\tBinit = tf.constant(0.0, shape=[outDim])\n",
    "\t\tB = tf.Variable(Binit)\n",
    "\t\tvariable_summaries(B, name + '/B')\n",
    "\t\ttensor = tf.nn.conv2d(tensor, W, strides=[1, stride, stride, 1], padding='SAME') + B\n",
    "\t\ttf.summary.image(name+'_Filtre1', tensor[:,:,:,0:1], 5)\n",
    "\t\ttensor = act(tensor)\n",
    "\t\tif KP_dropout != 1.0:\n",
    "\t\t\ttensor = tf.cond(IsTrainingMode,lambda: tf.nn.dropout(tensor, KP_dropout), lambda: tf.identity(tensor))\t\n",
    "\n",
    "\treturn tensor\n",
    "\n",
    "def maxpool(tensor, poolSize, name):\n",
    "\twith tf.name_scope(name):\n",
    "\t\ttensor = tf.nn.max_pool(tensor, ksize=(1,poolSize,poolSize,1), strides=(1,poolSize,poolSize,1), padding='SAME')\n",
    "\treturn tensor\n",
    "\t\n",
    "def flat(tensor):\n",
    "\tinDimH = tensor.get_shape()[1].value\n",
    "\tinDimW = tensor.get_shape()[2].value\n",
    "\tinDimD = tensor.get_shape()[3].value\n",
    "\ttensor = tf.reshape(tensor, [-1, inDimH * inDimW * inDimD])\n",
    "\tprint ('flat output  ',tensor)\n",
    "\treturn tensor\n",
    "\n",
    "def unflat(tensor, outDimH,outDimW,outDimD):\n",
    "\ttensor = tf.reshape(tensor, [-1,outDimH,outDimW,outDimD])\n",
    "\ttf.summary.image('input', tensor, 5)\n",
    "\tprint ('unflat output  ',tensor)\n",
    "\treturn tensor\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T13:45:13.634402Z",
     "start_time": "2019-02-07T13:38:45.524835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb data :  10000\n",
      "nb data :  10000\n",
      "unflat output   Tensor(\"CNN_1/Reshape:0\", shape=(?, 48, 48, 1), dtype=float32)\n",
      "conv_3_0 input   Tensor(\"CNN_1/Reshape:0\", shape=(?, 48, 48, 1), dtype=float32)\n",
      "conv_3_0 W   (3, 3, 1, 3)\n",
      "conv_3_1 input   Tensor(\"CNN_1/conv_3_0/cond/Merge:0\", shape=(?, 48, 48, 3), dtype=float32)\n",
      "conv_3_1 W   (3, 3, 3, 3)\n",
      "conv_6_0 input   Tensor(\"CNN_1/pool/MaxPool:0\", shape=(?, 24, 24, 3), dtype=float32)\n",
      "conv_6_0 W   (3, 3, 3, 6)\n",
      "conv_6_1 input   Tensor(\"CNN_1/conv_6_0/cond/Merge:0\", shape=(?, 24, 24, 6), dtype=float32)\n",
      "conv_6_1 W   (3, 3, 6, 6)\n",
      "conv_12_0 input   Tensor(\"CNN_1/pool_1/MaxPool:0\", shape=(?, 12, 12, 6), dtype=float32)\n",
      "conv_12_0 W   (3, 3, 6, 12)\n",
      "conv_12_1 input   Tensor(\"CNN_1/conv_12_0/cond/Merge:0\", shape=(?, 12, 12, 12), dtype=float32)\n",
      "conv_12_1 W   (3, 3, 12, 12)\n",
      "conv_24_0 input   Tensor(\"CNN_1/pool_2/MaxPool:0\", shape=(?, 6, 6, 12), dtype=float32)\n",
      "conv_24_0 W   (3, 3, 12, 24)\n",
      "conv_24_1 input   Tensor(\"CNN_1/conv_24_0/cond/Merge:0\", shape=(?, 6, 6, 24), dtype=float32)\n",
      "conv_24_1 W   (3, 3, 24, 24)\n",
      "flat output   Tensor(\"CNN_1/Reshape_1:0\", shape=(?, 216), dtype=float32)\n",
      "fc_2 input   Tensor(\"CNN_1/Reshape_1:0\", shape=(?, 216), dtype=float32)\n",
      "fc_2 W   (216, 2)\n",
      "INFO:tensorflow:Summary name cross entropy is illegal; using cross_entropy instead.\n",
      "-----------------------------------------------------\n",
      "----------- 10k_Dr0.900\n",
      "-----------------------------------------------------\n",
      "it=      0 - rate= 0.001000 - cross_entropy= 0.346295 - acc= 0.562500\n",
      "it=     10 - rate= 0.001000 - cross_entropy= 0.346250 - acc= 0.562500\n",
      "it=     20 - rate= 0.001000 - cross_entropy= 0.346722 - acc= 0.492188\n",
      "it=     30 - rate= 0.001000 - cross_entropy= 0.346698 - acc= 0.500000\n",
      "it=     40 - rate= 0.001000 - cross_entropy= 0.343622 - acc= 0.609375\n",
      "it=     50 - rate= 0.001000 - cross_entropy= 0.343734 - acc= 0.570312\n",
      "mean accuracy train = 0.523100  test = 0.523200\n",
      "it=     60 - rate= 0.001000 - cross_entropy= 0.347338 - acc= 0.492188\n",
      "it=     70 - rate= 0.001000 - cross_entropy= 0.349526 - acc= 0.421875\n",
      "it=     80 - rate= 0.001000 - cross_entropy= 0.345273 - acc= 0.585938\n",
      "it=     90 - rate= 0.001000 - cross_entropy= 0.346106 - acc= 0.523438\n",
      "it=    100 - rate= 0.001000 - cross_entropy= 0.346033 - acc= 0.523438\n",
      "it=    110 - rate= 0.001000 - cross_entropy= 0.344006 - acc= 0.570312\n",
      "it=    120 - rate= 0.001000 - cross_entropy= 0.342764 - acc= 0.593750\n",
      "it=    130 - rate= 0.001000 - cross_entropy= 0.346904 - acc= 0.507812\n",
      "it=    140 - rate= 0.001000 - cross_entropy= 0.346030 - acc= 0.523438\n",
      "it=    150 - rate= 0.001000 - cross_entropy= 0.346361 - acc= 0.515625\n",
      "mean accuracy train = 0.523100  test = 0.523200\n",
      "it=    160 - rate= 0.001000 - cross_entropy= 0.345001 - acc= 0.554688\n",
      "it=    170 - rate= 0.001000 - cross_entropy= 0.346916 - acc= 0.500000\n",
      "it=    180 - rate= 0.001000 - cross_entropy= 0.343725 - acc= 0.578125\n",
      "it=    190 - rate= 0.001000 - cross_entropy= 0.347394 - acc= 0.492188\n",
      "it=    200 - rate= 0.001000 - cross_entropy= 0.346792 - acc= 0.507812\n",
      "it=    210 - rate= 0.001000 - cross_entropy= 0.348596 - acc= 0.476562\n",
      "it=    220 - rate= 0.001000 - cross_entropy= 0.344875 - acc= 0.546875\n",
      "it=    230 - rate= 0.001000 - cross_entropy= 0.348401 - acc= 0.468750\n",
      "it=    240 - rate= 0.001000 - cross_entropy= 0.346335 - acc= 0.515625\n",
      "it=    250 - rate= 0.001000 - cross_entropy= 0.345744 - acc= 0.531250\n",
      "mean accuracy train = 0.523100  test = 0.523200\n",
      "it=    260 - rate= 0.001000 - cross_entropy= 0.345681 - acc= 0.531250\n",
      "it=    270 - rate= 0.001000 - cross_entropy= 0.346373 - acc= 0.515625\n",
      "it=    280 - rate= 0.001000 - cross_entropy= 0.344863 - acc= 0.546875\n",
      "it=    290 - rate= 0.001000 - cross_entropy= 0.347681 - acc= 0.492188\n",
      "it=    300 - rate= 0.001000 - cross_entropy= 0.346407 - acc= 0.515625\n",
      "it=    310 - rate= 0.001000 - cross_entropy= 0.346682 - acc= 0.507812\n",
      "it=    320 - rate= 0.001000 - cross_entropy= 0.346922 - acc= 0.500000\n",
      "it=    330 - rate= 0.001000 - cross_entropy= 0.345070 - acc= 0.546875\n",
      "it=    340 - rate= 0.001000 - cross_entropy= 0.348469 - acc= 0.468750\n",
      "it=    350 - rate= 0.001000 - cross_entropy= 0.347083 - acc= 0.500000\n",
      "mean accuracy train = 0.523100  test = 0.523200\n",
      "it=    360 - rate= 0.001000 - cross_entropy= 0.346034 - acc= 0.523438\n",
      "it=    370 - rate= 0.001000 - cross_entropy= 0.346434 - acc= 0.515625\n",
      "it=    380 - rate= 0.001000 - cross_entropy= 0.348293 - acc= 0.476562\n",
      "it=    390 - rate= 0.001000 - cross_entropy= 0.349482 - acc= 0.437500\n",
      "it=    400 - rate= 0.001000 - cross_entropy= 0.344532 - acc= 0.562500\n",
      "it=    410 - rate= 0.001000 - cross_entropy= 0.347332 - acc= 0.492188\n",
      "it=    420 - rate= 0.001000 - cross_entropy= 0.347082 - acc= 0.500000\n",
      "it=    430 - rate= 0.001000 - cross_entropy= 0.342093 - acc= 0.609375\n",
      "it=    440 - rate= 0.001000 - cross_entropy= 0.343602 - acc= 0.570312\n",
      "it=    450 - rate= 0.001000 - cross_entropy= 0.347619 - acc= 0.492188\n",
      "mean accuracy train = 0.523100  test = 0.523200\n",
      "it=    460 - rate= 0.001000 - cross_entropy= 0.350845 - acc= 0.421875\n",
      "it=    470 - rate= 0.001000 - cross_entropy= 0.343588 - acc= 0.585938\n",
      "it=    480 - rate= 0.001000 - cross_entropy= 0.346037 - acc= 0.523438\n",
      "it=    490 - rate= 0.001000 - cross_entropy= 0.346028 - acc= 0.523438\n",
      "it=    500 - rate= 0.001000 - cross_entropy= 0.343921 - acc= 0.570312\n",
      "it=    510 - rate= 0.001000 - cross_entropy= 0.342739 - acc= 0.593750\n",
      "it=    520 - rate= 0.001000 - cross_entropy= 0.346849 - acc= 0.507812\n",
      "it=    530 - rate= 0.001000 - cross_entropy= 0.346027 - acc= 0.523438\n",
      "it=    540 - rate= 0.001000 - cross_entropy= 0.346382 - acc= 0.515625\n",
      "it=    550 - rate= 0.001000 - cross_entropy= 0.344815 - acc= 0.554688\n",
      "mean accuracy train = 0.523100  test = 0.523200\n",
      "it=    560 - rate= 0.001000 - cross_entropy= 0.346986 - acc= 0.500000\n",
      "it=    570 - rate= 0.001000 - cross_entropy= 0.343627 - acc= 0.578125\n",
      "it=    580 - rate= 0.001000 - cross_entropy= 0.347433 - acc= 0.492188\n",
      "it=    590 - rate= 0.001000 - cross_entropy= 0.346773 - acc= 0.507812\n",
      "it=    600 - rate= 0.001000 - cross_entropy= 0.348501 - acc= 0.476562\n",
      "it=    610 - rate= 0.001000 - cross_entropy= 0.344872 - acc= 0.546875\n",
      "it=    620 - rate= 0.001000 - cross_entropy= 0.348467 - acc= 0.468750\n",
      "it=    630 - rate= 0.001000 - cross_entropy= 0.346350 - acc= 0.515625\n",
      "it=    640 - rate= 0.001000 - cross_entropy= 0.345709 - acc= 0.531250\n",
      "it=    650 - rate= 0.001000 - cross_entropy= 0.345675 - acc= 0.531250\n",
      "mean accuracy train = 0.523100  test = 0.523200\n",
      "it=    660 - rate= 0.001000 - cross_entropy= 0.346378 - acc= 0.515625\n",
      "it=    670 - rate= 0.001000 - cross_entropy= 0.344875 - acc= 0.546875\n",
      "it=    680 - rate= 0.001000 - cross_entropy= 0.347651 - acc= 0.492188\n",
      "it=    690 - rate= 0.001000 - cross_entropy= 0.346408 - acc= 0.515625\n",
      "it=    700 - rate= 0.001000 - cross_entropy= 0.346700 - acc= 0.507812\n",
      "it=    710 - rate= 0.001000 - cross_entropy= 0.346962 - acc= 0.500000\n",
      "it=    720 - rate= 0.001000 - cross_entropy= 0.345048 - acc= 0.546875\n",
      "it=    730 - rate= 0.001000 - cross_entropy= 0.348492 - acc= 0.468750\n",
      "it=    740 - rate= 0.001000 - cross_entropy= 0.347089 - acc= 0.500000\n",
      "it=    750 - rate= 0.001000 - cross_entropy= 0.346027 - acc= 0.523438\n",
      "mean accuracy train = 0.523100  test = 0.523200\n",
      "it=    760 - rate= 0.001000 - cross_entropy= 0.346428 - acc= 0.515625\n",
      "it=    770 - rate= 0.001000 - cross_entropy= 0.348294 - acc= 0.476562\n",
      "it=    780 - rate= 0.001000 - cross_entropy= 0.349593 - acc= 0.437500\n",
      "it=    790 - rate= 0.001000 - cross_entropy= 0.344472 - acc= 0.562500\n",
      "it=    800 - rate= 0.001000 - cross_entropy= 0.347361 - acc= 0.492188\n",
      "it=    810 - rate= 0.001000 - cross_entropy= 0.347089 - acc= 0.500000\n",
      "it=    820 - rate= 0.001000 - cross_entropy= 0.342071 - acc= 0.609375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-1e8cb971a77a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbIt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mtrainDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mIsTrainingMode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_dict(database,IsTrainingMode):\n",
    "\txs,ys = database.NextTrainingBatch()\n",
    "\treturn {x:xs,y_desired:ys,ITM:IsTrainingMode}\n",
    "\n",
    "LoadModel = False\n",
    "KeepProb_Dropout = 0.9\n",
    "\n",
    "experiment_name = '10k_Dr%.3f'%KeepProb_Dropout\n",
    "#train = ds.DataSet('../DataBases/data_1k.bin','../DataBases/gender_1k.bin',1000)\n",
    "train = DataSet('/Users/maelfabien/Desktop/LocalDB/MDI341/Databases/data_10k.bin','/Users/maelfabien/Desktop/LocalDB/MDI341/Databases/gender_10k.bin',10000)\n",
    "#train = ds.DataSet('../DataBases/data_100k.bin','../DataBases/gender_100k.bin',100000)\n",
    "test = DataSet('/Users/maelfabien/Desktop/LocalDB/MDI341/Databases/data_10k.bin','/Users/maelfabien/Desktop/LocalDB/MDI341/Databases/gender_10k.bin',10000)\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "\tx = tf.placeholder(tf.float32, [None, train.dim],name='x')\n",
    "\ty_desired = tf.placeholder(tf.float32, [None, 2],name='y_desired')\n",
    "\tITM = tf.placeholder(\"bool\", name='Is_Training_Mode')\n",
    "\n",
    "with tf.name_scope('CNN'):\n",
    "\tt = unflat(x,48,48,1)\n",
    "\tnbfilter = 3\n",
    "\tfor k in range(4):\n",
    "\t\tfor i in range(2):\n",
    "\t\t\tt = conv(t,nbfilter,3,1,ITM,'conv_%d_%d'%(nbfilter,i),KeepProb_Dropout)\n",
    "\t\tt = maxpool(t,2,'pool')\n",
    "\t\tnbfilter *= 2\n",
    "\t\n",
    "\tt = flat(t)\n",
    "\t#t = Layers.fc(t,50,ITM,'fc_1',KeepProb_Dropout)\n",
    "\ty = fc(t,2,ITM,'fc_2',KP_dropout=1.0,act=tf.nn.log_softmax)\n",
    "\n",
    "with tf.name_scope('cross_entropy'):\n",
    "\tdiff = y_desired * y \n",
    "\twith tf.name_scope('total'):\n",
    "\t\tcross_entropy = -tf.reduce_mean(diff)\n",
    "\ttf.summary.scalar('cross entropy', cross_entropy)\t\n",
    "\t\n",
    "with tf.name_scope('accuracy'):\n",
    "\twith tf.name_scope('correct_prediction'):\n",
    "\t\tcorrect_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_desired, 1))\n",
    "\twith tf.name_scope('accuracy'):\n",
    "\t\taccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\ttf.summary.scalar('accuracy', accuracy)\t\n",
    "\n",
    "with tf.name_scope('learning_rate'):\n",
    "\tglobal_step = tf.Variable(0, trainable=False)\n",
    "\tlearning_rate = tf.train.exponential_decay(1e-3,global_step,1000, 0.75, staircase=True)\n",
    "\n",
    "\n",
    "with tf.name_scope('learning_rate'):\n",
    "    tf.summary.scalar('learning_rate', learning_rate)\n",
    "\n",
    "#train_step = tf.train.GradientDescentOptimizer(0.00001).minimize(cross_entropy)\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy,global_step=global_step)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "Acc_Train = tf.placeholder(\"float\", name='Acc_Train');\n",
    "Acc_Test = tf.placeholder(\"float\", name='Acc_Test');\n",
    "MeanAcc_summary = tf.summary.merge([tf.summary.scalar('Acc_Train', Acc_Train),tf.summary.scalar('Acc_Test', Acc_Test)])\n",
    "\n",
    "\n",
    "print (\"-----------------------------------------------------\")\n",
    "print (\"-----------\",experiment_name)\n",
    "print (\"-----------------------------------------------------\")\n",
    "\n",
    "sess = tf.Session()\t\n",
    "sess.run(tf.global_variables_initializer())\n",
    "writer = tf.summary.FileWriter(experiment_name, sess.graph)\n",
    "saver = tf.train.Saver()\n",
    "if LoadModel:\n",
    "\tsaver.restore(sess, \"./model.ckpt\")\n",
    "\n",
    "nbIt = 5000\n",
    "for it in range(nbIt):\n",
    "\ttrainDict = get_dict(train,IsTrainingMode=True)\t\t\t\t\t\n",
    "\tsess.run(train_step, feed_dict=trainDict)\n",
    "\t\n",
    "\tif it%10 == 0:\n",
    "\t\tacc,ce,lr = sess.run([accuracy,cross_entropy,learning_rate], feed_dict=trainDict)\n",
    "\t\tprint (\"it= %6d - rate= %f - cross_entropy= %f - acc= %f\" % (it,lr,ce,acc ))\n",
    "\t\tsummary_merged = sess.run(merged, feed_dict=trainDict)\n",
    "\t\twriter.add_summary(summary_merged, it)\t\n",
    "\t\t\t\t\n",
    "\tif it%100 == 50:\n",
    "\t\tAcc_Train_value = train.mean_accuracy(sess,accuracy,x,y_desired,ITM)\n",
    "\t\tAcc_Test_value = test.mean_accuracy(sess,accuracy,x,y_desired,ITM)\n",
    "\t\tprint (\"mean accuracy train = %f  test = %f\" % (Acc_Train_value,Acc_Test_value ))\n",
    "\t\tsummary_acc = sess.run(MeanAcc_summary, feed_dict={Acc_Train:Acc_Train_value,Acc_Test:Acc_Test_value})\n",
    "\t\twriter.add_summary(summary_acc, it)\n",
    "\t\t\n",
    "writer.close()\n",
    "if not LoadModel:\n",
    "\tsaver.save(sess, \"./model.ckpt\")\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
